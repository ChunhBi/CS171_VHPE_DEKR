{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils.visual import *\n",
    "import torch\n",
    "from utils.dataset import HybridDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "# dir_path=r\"H:\\test\\0802_full\\5\"\n",
    "dir_path=r\"..\\littletestset\\5\"\n",
    "set_name=\"5\"\n",
    "frame_num = 20\n",
    "out_dir=r\"..\\outputs\"\n",
    "device = torch.device(\"cuda:0\")\n",
    "hyb=HybridDataset(dir_path,360)\n",
    "# Ri2w=hyb.load_Ri2w(osp.join(dir_path,\"I2C.txt\"))\n",
    "shape=hyb.load_shape(osp.join(dir_path,\"shape.txt\"))\n",
    "first_fram, pose_batch=hyb.load_gt_seq(osp.join(dir_path,\"pose.txt\"))\n",
    "Gw2c_list,K_list,view_name_list=hyb.load_Gw2c(r\"..\\calibration.json\")\n",
    "# joints2d=hyb.load_joints2d( dir_path, [\"data3\"], 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: You are using a SMPL model, with only 10 shape coefficients.\n"
     ]
    }
   ],
   "source": [
    "from models import *\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "smpl = SMPL(SMPL_MODEL_DIR, create_transl=False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_batch=torch.from_numpy(pose_batch).to(device)\n",
    "shape=torch.from_numpy(shape).to(device)\n",
    "\n",
    "output = smpl(betas=shape.repeat([pose_batch.shape[0], 1]),\n",
    "              body_pose=pose_batch[:,6:],\n",
    "              global_orient=pose_batch[:,3:6],\n",
    "              transl=pose_batch[:,:3], return_vertices=False)\n",
    "output=output.joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_list = []\n",
    "for i in range(len(view_name_list)):\n",
    "    K_ori = K_list[i]\n",
    "    K = np.zeros((K_ori.shape[0], K_ori.shape[1] + 1), dtype=np.float32)\n",
    "    K[:, :-1] = K_ori\n",
    "    proj = K.dot(Gw2c_list[i])\n",
    "    #proj = K.dot(Gw2c_list[i])\n",
    "    proj_list.append(proj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection(output,view):\n",
    "    joints3d=torch.ones((output.shape[0],1,output.shape[1]),dtype=torch.float32,device=device)\n",
    "    joints3d=torch.cat([output.permute(0,2,1),joints3d],1)\n",
    "    joints2d=torch.einsum(\"mn,snl->sml\",torch.from_numpy(proj_list[view]).to(device),joints3d)\n",
    "    joints2d=joints2d/joints2d[...,2:3,:]\n",
    "    joints2d=joints2d.permute([0,2,1])\n",
    "    return joints2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints2d_list=[]\n",
    "for view in range(len(proj_list)):\n",
    "    joints2d=projection(output,view)\n",
    "    joints2d_list.append(joints2d)\n",
    "\n",
    "# joints2d_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file=dict()\n",
    "\n",
    "keypoints=['nose','left_eye','right_eye','left_ear','right_ear','left_shoulder','right_shoulder','left_elbow','right_elbow','left_wrist',\n",
    "           'right_wrist','left_hip','right_hip','left_knee','right_knee','left_ankle','right_ankle']\n",
    "keypoints_map=dict()\n",
    "for i,key in enumerate(keypoints):\n",
    "    keypoints_map[key]=i\n",
    "skeleton=[[16, 14],\n",
    "   [14, 12],\n",
    "   [17, 15],\n",
    "   [15, 13],\n",
    "   [12, 13],\n",
    "   [6, 12],\n",
    "   [7, 13],\n",
    "   [6, 7],\n",
    "   [6, 8],\n",
    "   [7, 9],\n",
    "   [8, 10],\n",
    "   [9, 11],\n",
    "   [2, 3],\n",
    "   [1, 2],\n",
    "   [1, 3],\n",
    "   [2, 4],\n",
    "   [3, 5],\n",
    "   [4, 6],\n",
    "   [5, 7]]\n",
    "json_file[\"categories\"]=[{\"supercategory\": \"person\",\"id\": 1,\"name\": \"person\",\"keypoints\":keypoints,\"skeleton\": skeleton}]\n",
    "json_file['images']=[]\n",
    "json_file[\"annotations\"]=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from subprocess import run\n",
    "import os\n",
    "import os.path as osp\n",
    "if not osp.exists(out_dir):\n",
    "    os.mkdir(out_dir)\n",
    "result_dir=osp.join(out_dir,set_name)\n",
    "if not osp.exists(result_dir):\n",
    "    os.mkdir(result_dir)\n",
    "\n",
    "json_list = []\n",
    "# here 1,10 means video data1 to data10\n",
    "for num in range(1,len(proj_list)+1):\n",
    "    video_name=\"data\"+str(num)+\".mp4\"\n",
    "    if video_name not in os.listdir(dir_path):\n",
    "        continue\n",
    "\n",
    "    bundle_dir=osp.join(result_dir, \"data\"+str(num))\n",
    "    if not osp.exists(bundle_dir):\n",
    "        os.mkdir(bundle_dir)\n",
    "    img_dir = osp.join(bundle_dir, set_name + \"_data\" + str(num))\n",
    "    if not osp.exists(img_dir):\n",
    "        os.mkdir(img_dir)\n",
    "\n",
    "    temp = json_file.copy()\n",
    "    \n",
    "    video_path=osp.join(dir_path,\"data\"+str(num)+\".mp4\")\n",
    "    name_prefix=set_name + \"%02d\"%num\n",
    "    unpack_cmd = 'ffmpeg -i ' + video_path + ' -r ' + str(frame_num) + ' -f image2 ' +img_dir+ '\\\\'+name_prefix+'%04d.jpg'\n",
    "    # unpack_cmd = 'ffmpeg -i ' + video_path + ' -f image2 ' +img_dir+ '\\\\'+name_prefix+'%04d.jpg'\n",
    "    run(unpack_cmd)\n",
    "    os.chdir(out_dir)\n",
    "\n",
    "    mul = (60//frame_num)\n",
    "    first = first_fram//mul + 1\n",
    "    for i in range(joints2d_list[num-1].shape[0]//mul):\n",
    "        # index=i+first_fram\n",
    "        index = i + first\n",
    "        img_id=name_prefix+\"%04d\"%index\n",
    "        img_name=img_id+\".jpg\"\n",
    "        temp['images'].append({\"file_name\":img_name,\"id\":int(img_id),\"height\": 2160,\"width\": 4096})\n",
    "        keypoints=[int(p) for p in joints2d_list[num-1][i][[13,15,16,17,18,8,9,4,5,0,1,10,12,6,7,2,3]].reshape(-1).cpu().numpy()]\n",
    "        l_bound=int(torch.min(joints2d_list[0][i*mul,:,0]).cpu().numpy())\n",
    "        r_bound=int(torch.max(joints2d_list[0][i*mul,:,0]).cpu().numpy())\n",
    "        d_bound=int(torch.min(joints2d_list[0][i*mul,:,1]).cpu().numpy())\n",
    "        u_bound=int(torch.max(joints2d_list[0][i*mul,:,1]).cpu().numpy())\n",
    "        temp[\"annotations\"].append({\"num_keypoints\": 17,\"iscrowd\": 0,\"keypoints\":keypoints,\"image_id\":int(img_id),\"bbox\":[r_bound,u_bound,l_bound,d_bound],\"category_id\": 1,\"id\":int(img_id),\"area\":(r_bound-l_bound)*(u_bound-d_bound)/2})\n",
    "\n",
    "    with open(osp.join(bundle_dir,\"person_keypoints_\"+set_name + \"_data\" + str(num)+\".json\"),\"w\") as f:\n",
    "        json.dump(temp,f) \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9faeb125cd6c8e56807a56ba67eb8ddfebed7108447177a6c492c8ed57911cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
